	\documentclass[10pt,oneside]{CBFT_book}
	% Algunos paquetes
	\usepackage{amssymb}
	\usepackage{amsmath}
	\usepackage{graphicx}
	\usepackage{libertine}
	\usepackage[bold-style=TeX]{unicode-math}
	\usepackage{lipsum}

	\usepackage{natbib}
	\setcitestyle{square}

	\usepackage{polyglossia}
	\setdefaultlanguage{spanish}
	



	\usepackage{CBFT.estilo} % Cargo la hoja de estilo

	% Tipografías
	% \setromanfont[Mapping=tex-text]{Linux Libertine O}
	% \setsansfont[Mapping=tex-text]{DejaVu Sans}
	% \setmonofont[Mapping=tex-text]{DejaVu Sans Mono}

	%===================================================================
	%	DOCUMENTO PROPIAMENTE DICHO
	%===================================================================

\begin{document}

% =================================================================================================
\chapter{Básicos de termodinámica}
% =================================================================================================


% =================================================================================================
\section{Energía y entropía}
% =================================================================================================

Una de las formulaciones de la 2da ley es definir la entropía. Surge de:
\[
	\frac{Q_1}{Q_2} = -\frac{T_1}{T_2} \qquad \Rightarrow \frac{Q_1}{Q_2} + \frac{T_1}{T_2} = 0 \;
	\text{reversible}
\]
\[
	\int \frac{dQ}{T} \leq 0 \qquad \text{desigualdad de Clausius}
\] 
Proceso reversible en un sistema aislado
\[
	S_{A\to B} = \int_A^B dS = 0
\]
pues 
\[
	dS =\frac{dU}{T} - \frac{p}{V}dV + \frac{\mu}{T}dN = 0
\]
pero en procesos irreversibles la variación de $S$ es cota superior:
\notamargen{La existencia de $S$ es independiente de su cálculo}
\[
	\int_A^B \frac{dQ}{T} < \int_A^B dS = S_{A\to B}.
\]

Luego, para un sistema aislado, en un proceso irreversible 
\[
	dS_I = 0 \qquad \Rightarrow \qquad \frac{dQ_I}{T} = 0
\]
y entonces
\[
	0 < \int_A^B  dS =  S_{A\to B}
\]

La entropía solo aumenta. Podría calcular $S_{A\to B}$ con un proceso reversible de $A\to B$ pero ahí 
ya tengo que intervenir sobre el sistema (no hay procesos espontáneos --en un sistema aislado-- reversibles).

En reversibles
\[
	dU = TdS - pdV + \mu dN
\]
mientras que en irreversibles
\[
	dU = ddQ_I - pdV +\mu dN, \quad \text{pero} \quad dQ_I < TdS 
\]
y entonces
\[
	dU < TdS - pdV + \mu dN
\]
% \begin{figure}[htb]
% 	\begin{center}
% 	\includegraphics[width=0.8\textwidth]{images/teo2_1.pdf}	 
% 	\end{center}
% 	\caption{}
% \end{figure} 
Si $S$ es homogénea, se tiene
\[
	S = S(\lambda U, \lambda X, \{\lambda N_i\}) = \lambda S( U, X, \{ N_i\})
\]
y además si \notamargen{En un sistema $PVT$ $Y=-p$.}
\[
	TdS = dU - YdX - \mu_i dN_i
\]
\[
	\dtot{S}{\lambda} = S = \dpar{S}{\lambda U}\dtot{\lambda U}{\lambda} +
	\dpar{S}{\lambda X}\dtot{\lambda X}{\lambda} +
	\dpar{S}{\lambda N_i}\dtot{\lambda N_i}{\lambda}
\]
\[
	S = \dpar{S}{\lambda U} U + \dpar{S}{\lambda X} X + \dpar{S}{\lambda N_i} N_i
\]
\[
	\dpar{}{\lambda U}\left[ S(\lambda U)\right] = 
	\dpar{}{\lambda U}\left[ \lambda S( U)\right] = \dpar{S}{U} = \frac{1}{T}
\]
y procediendo del mismo modo con $Y,\mu$
\[
	S = \frac{1}{T} U + \frac{-Y}{T} X + \frac{-\mu_i}{T} N_i
\]
y arribamos a la ecuación fundamental
\[
	TS = U - YX - \mu_i N_i 
\]
o bien
\[
	U = TS + YX + \sum_i \mu_i N_i
\]

La primera ley (en sistemas reversibles) era 
\[
	dU = TdS + YdX + \sum_i \mu_i dN_i
\]
y a $S,V,N$ constantes 
\[
	dU^R = 0 \qquad dU^I \leq 0
\]
la mínima $U$ es equilibrio.
Si existe trabajo que no es de volumen resulta 
\[
	dU < -dW_\text{libre}
\]
\[
	\frac{dQ}{dT} = \frac{dU}{T} + \frac{p}{T}dV - \frac{\mu}{T}dN = \frac{dQ}{dT} \leq dS
\]

Si el sistema está aislado será
\[
	0 \leq dS \quad \text{condición de equilibrio}
\]
alcanzando el máximo ya no puede disminuir la entropía.


% =================================================================================================
\section{Transformadas de Legendre de las funciones termodinámicas}
% =================================================================================================

\[
	f(x,y,z) \qquad \text{con pendientes} \quad \dpar{f}{x},\dpar{f}{y},\dpar{f}{z}
\]
entonces 
\[
	\varphi(f_x,y,z) = f(x,y,z) - \left. x \dpar{f(x,y,z)}{x}\right|_{y,z}
\]
es la transformada de Legendre respecto de $x$, mientras que 
\[
	\varphi(f_x,f_y,z) = f(x,y,z) - x \dpar{f}{x} - y \dpar{f}{y}
\]
es la transformada de Legendre respecto de $y$.

La transformada de Legendre transforma una función homogénea en otra función homogénea, mantiene el
carácter de función de estado.
\[
	d\varphi(f_x,y,z) = df - dx \dpar{f}{x} - x d\left( \dpar{f}{y} \right)
\]

Para el caso de la energía
\[
	U=U(S,V,N) \qquad \qquad dU = TdS - pdV + \mu dN
\]
y entonces
\[
	A = U - \left. S\dpar{U}{S}\right|_{V,N} = U - ST \Rightarrow A=A(T,V,N)
\]
% \[
% 	\left( \frac{1}{\sqrt{2}} \Bra{x} + \frac{1}{\sqrt{2}} \Bra{y}  \right)
% 	\left( \Ket{x} \right)= \frac{1}{\sqrt{2}}
% \]
% 
% \subsection{Propiedades}
% 
% \begin{enumerate}
%  \item $\Braket{\beta|\alpha} = \Braket{\beta|\alpha}^*$ \text{luego} $ \Braket{\alpha|\alpha} \; \in \mathbb{R}$
%  \item $\Braket{\alpha|\alpha} \geq 0$ \text{métrica definida positiva}
%  \item $\Braket{\alpha|\beta} = \Braket{\beta|\alpha} = 0 \Leftrightarrow \Ket{\alpha} \perp \Ket{\beta}$
%  \item $\Braket{\tilde{\alpha}|\tilde{\alpha}} = 1 \; \text{con} \; 
%  \Ket{\tilde{\alpha}} = \frac{1}{\sqrt{\Braket{\alpha|\alpha}}}\Ket{\alpha} $ todo ket no nulo es normalizable
% \end{enumerate}
% 
% \subsection{Operadores}
% 
% A cada observable lo representaremos por un operador. hay operaradores que no vienen de observables.
% \[
% 	\hat{A}\Ket{\alpha} = \Ket{\gamma} \qquad \qquad  \Bra{\alpha} \hat{A} = \Bra{\gamma}
% \]
% un operador sobre un ket da otro ket y sobre un bra da otro bra. Notemos que en este último caso opera 
% a izquierda. La transformación entre operadores se da con 
% \[
% 	\hat{X}\Ket{a} \Leftrightarrow \Bra{a}\hat{X}^\dagger
% \]
% donde $\dagger$ (daga) significa el traspuesto conjugado; cambia el sentido hacia donde actúa el operador 
% y conjuga. Se da que si 
% \[
% 	\hat{X} = \hat{X}^\dagger \quad \Rightarrow \qquad \hat{X} \;\text{es hermítico}
% \]
% Se dan 
% \begin{itemize}
%  \item $\hat{X}\hat{Y} \neq \hat{Y}\hat{X} \qquad \qquad \text{no conmutativo}$
%  \item $\hat{X}(\hat{Y}\hat{Z}) = (\hat{X}\hat{Y})\hat{Z} = \hat{X}\hat{Y}\hat{Z} \qquad \qquad \text{asociativo}$
%  \item $(XY)^\dagger = Y^\dagger X^\dagger$
%  \item $\hat{0}\Ket{\alpha} = 0 \qquad \forall \Ket{\alpha}$ ; $\hat{0} \equiv$ operador nulo
%  \item $\hat{X}( c_1 \Ket{\alpha} + c_2 \Ket{\beta} ) = c_1 \hat{X}\Ket{\alpha} + c_2 \hat{X}\Ket{\beta} $
% \end{itemize}
% 
% de modo que en cuántica los observables se representan mediante operadores hermíticos.
% 
% \subsection{sandwichs}
% 
% \[
% 	\Braket{\beta|X|\alpha} = (\Bra{\beta})(X\Ket{\alpha}) = \Braket{\beta|\gamma} =
% 	\Braket{\gamma|\beta}^* = (\Braket{\alpha|X|\beta})^*
% \]
% donde usamos que $\Ket{\gamma}$ es un ket y por dual conjugado $\Bra{\gamma} = \Bra{\alpha}\hat{X}^\dagger$ y
% extraemos como conclusión 
% \[
% 	\Braket{\beta|X|\alpha} = (\Braket{\alpha|X|\beta})^*
% \]
% y de manera equivalente
% \[
% 	\Braket{\beta|X|\alpha} = (\Bra{\beta}X^\dagger)(\Ket{\alpha}) = \Braket{\Gamma|\alpha} =
% 	\Braket{\alpha|\Gamma}^* = (\Braket{\alpha|X^\dagger|\beta})^*
% \]
% donde usamos que $\Bra{\Gamma}$ es un bra y por dual conjugado $\Ket{\Gamma} = \hat{X}\Ket{\beta}$.
% El formalismo parece ser consistente. El operador opera sobre un ket/bra y multiplica al otro.
% 
% 
% \subsection{Producto externo}
% 
% \[
% 	\Ket{\beta} \Bra{\alpha} \equiv (\Ket{\beta} )( \Bra{\alpha} )
% \]
% \[
% 	( \Ket{\beta} \Bra{\alpha} )\Ket{\gamma} = \Ket{\beta} \Bra{\alpha} \Ket{\gamma} =
% 		\Braket{\alpha|\gamma} \Ket{\beta} , 
% \]
% de modo que es un operador pues al aplicar sobre un ket obtengo otro ket (notemos que $\Braket{\alpha|\gamma}$
% es un escalar). Podemos pensar en que 
% \[
% 	\Lambda_\alpha \equiv \Ket{\alpha}\Bra{\alpha}
% \]
% es el proyector, que actúa rotando un $\Ket{\gamma}$ en la dirección de $\Ket{\beta}$. Notemos 
% \[
% 	\Lambda_\alpha^2 = \Ket{\alpha}\Bra{\alpha}\Ket{\alpha}\Bra{\alpha} = \Ket{\alpha}\Bra{\alpha} = \Lambda_\alpha
% \]
% puesto que $\Braket{\alpha|\alpha}=1$. El proyector $\Lambda_\alpha$ sobre un ket $\Ket{\beta}$ selecciona la parte de
% $\Ket{\beta}$ en la dirección de $\Ket{\alpha}$. Nos dice cuanto de $\Ket{\beta}$ está en la dirección de 
% $\Ket{\alpha}$.
% Luego,
% \[
% 	\sum_i^N \; \Lambda_i = \sum_i^N \; \Ket{i}\Bra{i} = \mathbb{1}
% \]
% la suma de todos los proyectores del espacio en el que estamos es la identidad de ese espacio. Decimos que $\Ket{i}$ es 
% un conjunto completo. Se verifica además
% \[
% 	(\Ket{\beta} \Bra{\alpha})^\dagger = \Ket{\alpha} \Bra{\beta}
% \]
% Algunas cuentitas de ejemplo en dos dimensiones,
% \[
% 	\hat{X} = \begin{pmatrix} 1 \\ 0 \end{pmatrix} \qquad \qquad \hat{Y} = \begin{pmatrix} 0 \\ 1 \end{pmatrix}
% \]
% \[
% 	\hat{X}^\dagger = ( 1 \; 0 ) \qquad \qquad \hat{Y}^\dagger = ( 0 \; 1  ) 
% \]
% \[
% 	\hat{X}^\dagger\hat{X} = (1 \; 0) \begin{pmatrix} 1 \\ 0 \end{pmatrix} = 1 \qquad 
% 	\hat{X}\hat{X}^\dagger = \begin{pmatrix} 1 \\ 0 \end{pmatrix} (1 \; 0) = 
% 	\begin{pmatrix} 1 & 0 \\ 0 & 0 \\ \end{pmatrix},
% \]
% donde instamos al lector a que note la diferencia de dimensión en los resultados.
% 
% Los kets $\Ket{\alpha}$ {\it viven} en un espacio vectorial de Hilbert con dimensión N, donde N lo dicta el número de 
% posibles estados de cada sistema físico. Una partícula de spín $1/2$ sólo tiene dos estados: up y down.
% Hay otro producto más, que se llama producto tensorial y se representa como 
% \[
% 	\Ket{\alpha} \otimes \Ket{\beta}
% \]
% que es un producto entre kets de espacios de Hilbert diferentes.
% \[
% 	\Braket{\alpha|\beta}^* \equiv DC\{\ket{\beta}\} DC\{\Bra{\alpha}\}
% \]
% 
% \section{Bases}
% 
% Dado un sistema físico representado por un espacio vectorial $\mathcal{H}$ de dimensión $N$ existirá una base (también 
% de dimensión $N$) que será un conjunto de estados tal que cualquier estado de ese sistema físico puede representarse 
% como combinación lineal de ese conjunto,
% \[
% 	\{ \Ket{i}\} \; \text{base} \quad \Rightarrow \; \Ket{\alpha} = \sum_i^N c_i \Ket{i}
% \]
% siendo $\Ket{\alpha}$ un estado cualquiera.
% Es práctico utilizar bases ortonormales,
% \[
% 	\Braket{ i|j } = \delta_{ij} = \begin{cases}
% 	                                1 \quad i=j \\
% 	                                0 \quad i\neq j
% 	                               \end{cases}
% \]
% que es la delta de Kronecker.
% 
% Así, los kets se definen normalizados.
% \[
% 	\Ket{\psi} = a \Ket{1} + b \Ket{2} + c \Ket{3} + d \Ket{4} \qquad\quad |a|^2 + |b|^2 +|c|^2 +|d|^2 = 1
% \]
% sea $\Ket{\phi} = a \Ket{1} + b \Ket{2}$, $\Bra{\phi} = a^*\Bra{1} + b^* \Bra{2}$ entonces 
% \[
% 	\Braket{\phi|\phi} = (a^*\Bra{1} + b^* \Bra{2})(a \Ket{1} + b \Ket{2}) = 
% 	a^*a \Braket{1|1} + b^*a\Braket{2|1} + a^*b\Braket{1|2} + b^*b\Braket{2|2} =
% 	|a|^2 + |b|^2 = 1
% \]
% 
% \subsection{Autokets y autovalores}
% 
% Si $\hat{A}\Ket{a}=c\Ket{a}$ entonces $\Ket{a}$ es autoket de $\hat{A}$ con autovalor $c$. Se suelen 
% etiquetar los autoestados $\Ket{a'}, \Ket{a''}$ de modo que 
% \[
% 	\hat{A}\Ket{a'} = a'\Ket{a'}
% \]
% lo cual lleva al problema espectral
% \[
% 	\left(\hat{A} - a'\mathbb{1}\right) \Ket{a'} = 0
% \]
% entonces los operadores tendrán representación matricial, que cambiará según la base utilizada.ñ
% Vamos viendo que en general sólo se sabe cómo opera un operador sobre kets. La operación sobre los
% bras la obtenemos usando dual conjugado.
% 
% Deducimos entonces que
% \begin{enumerate}
%  \item Los autovalores de un operador hermítico son reales y los autokets correspondientes a diferentes
%  autovalores son ortogonales.
%  \item Los autokets de un operador son base completa del espacio de kets.
% \end{enumerate}
% 
% Como ejemplo de A citemos
% \[
% 	a'\Ket{a'} = A\Ket{a'} \quad \text{DC} \quad \Bra{a'} A^{\dagger} = \Bra{a'} A = \Bra{a'}a'^*
% \]
% de manera que 
% \[
% 	\Braket{a'|A|a'} = ( \Bra{a'} )( A\Ket{|a'} ) = a'
% \]
% \[
% 	( \Braket{a'|A|a'} )^* = ( \Bra{a'} )( A\Ket{|a'} )^* = ( \Bra{|a'}A^\dagger )( \Ket{a'} )
% \]
% \[
% 	= \Braket{a'|A|a'} = a' \qquad \Rightarrow \quad a' = a'^*.
% \]
% 
% Para el caso de B se postula así. Si esto vale entonces 
% \[
% 	\Ket{\alpha} = \sum_i^N \Ket{a_i}\Bra{a_i} \Ket{\alpha} = \sum_i^N c_i \Ket{a_i} = 
% 	\mathbb{1}\Ket{\alpha}
% \]
% pues 
% \[
% 	\Braket{\alpha|\alpha} = \sum_{i,j}^N \Braket{ a_j|c_j^* c_i|a_i} = \sum_i^N |c_i|^2 = 1
% \]
% y además 
% \[
% 	A\Ket{a'} = a'\Ket{a'} \qquad A\Ket{a''} = a''\Ket{a''} \Rightarrow 
% 	A(\Ket{a'} - \Ket{a''} ) = a'\Ket{a'} - a''\Ket{a''}
% \]
% \[
% 	\Braket{ a''|A|a' } = a' \Braket{ a''|a' } \qquad \Braket{ a'|A|a'' } = a'' \Braket{ a'|a'' }
% \]
% y ahora conjugando
% \[
% 	\Braket{ a''|A|a' }^* = a' \Braket{ a''|a' }^* \qquad \Braket{ a''|A|a' } = a'' \Braket{ a''|a' }
% \]
% donde usamos que $a''^* = a''$ y restando 
% \[
% 	(a'-a'')\Braket{a''|a'} = 0 \qquad \Rightarrow \; \Braket{a''|a'} = 0 
% 		\quad \text{si} \quad a'\neq a''
% \]
% Si la base es completa entonces es $\sum \Lambda = 1$.
% 
% \subsection{Operadores y matrices}
% 
% Un operador se puede representar matricialmente como 
% \[
% 	X = \sum_{a'}^N  \sum_{a''}^N \Ket{a''} \Bra{a''} X \Ket{a'} \Bra{a'} =  
% 	\sum_{a'}^N  \sum_{a''}^N ( \Braket{a''|X|a'} ) \Ket{a''} \Bra{a'}
% \]
% donde hemos explotado el hecho de que en el medio aparece un escalar (?), siendo 
% \[
% 	X_{ij} = \Braket{a_i|X|a_j}
% \]
% un elemento de matriz. Y notemos que $\Ket{a''} \Bra{a'}$ es un ente de $N\times N$.
% Si la base es de dimensión 3 se tendrá por ejemplo,
% \[
% 	X = \begin{pmatrix}
% 	 x_{11} & x_{12} & x_{13} \\
% 	 x_{21} & x_{22} & x_{23} \\
% 	 x_{31} & x_{32} & x_{33} \\
% 	\end{pmatrix}
% \]
% de manera que existe una identificación entre cosas del álgebra básica y este mundo
% de operadores y estados.
% Si $X$ es hermítico por ejemplo, entonces su matriz es simétrica conjugada.
% \[
% 	\Braket{a_i|X|a_j}^* = (\Bra{a_j}X^\dagger)(\Ket{a_i}) = \Braket{a_j|X|a_i}
% \]
% y entonces 
% \[
% 	\Braket{a_j|X|a_i}^* = \Braket{a_i|X|a_j}
% \]
% de modo que 
% \[
% 	X_{ji}^* = X_{ij} \qquad X_{ij}^{t*} = X_{ij} \qquad X_{ij}^\dagger=X_{ij}
% \]
% y vemos bien el significado de {\it daguear}. En este caso la matriz tiene traza real
% y seis elementos independientes
% \[
% 	X = \begin{pmatrix}
% 	  X_{11} & X_{12} & X_{13} \\
% 	  X_{12}^* & X_{22} & X_{23} \\
% 	  X_{13}^* & X_{23}^* & X_{33} \\
% 	\end{pmatrix} =
% 	\begin{pmatrix}
% 	  X_{11} & X_{12} & X_{13} \\
% 	  X_{21} & X_{22} & X_{23} \\
% 	  X_{31} & X_{32} & X_{33} \\
% 	\end{pmatrix} =
% 	\begin{pmatrix}
% 	  X_{11}^* & X_{21}^* & X_{31}^* \\
% 	  X_{12}^* & X_{22}^* & X_{32}^* \\
% 	  X_{13}^* & X_{12}^* & X_{33}^* \\
% 	\end{pmatrix}
% \]
% 
% \subsection{Combinación lineal de autoestados}
% 
% Un estado $\Ket{\alpha}$ se puede escribir en función de la base $\Ket{a_i}$ de esta forma 
% \[
% 	\Ket{\alpha} = \sum_{i=1}^N \Ket{a_i}\Braket{a_i|\alpha} = 
% 		\sum_{i=1}^N (\Braket{a_i|\alpha}) \Ket{a_i}
% \]
% y entonces
% \[
% 	\Braket{a_i|\alpha} = \sum_{i=1}^N c_i \underbrace{\Braket{a_j|a_i}}_{\delta_{ij}} = c_j 
% \]
% 
% \subsection{Cambio de base}
% 
% Para cambiar de base metemos un uno ($\mathbb{1}$) escrito como suma de proyectores,
% \[
% 	X\Ket{b_j} = \sum_{i=1}^N \Ket{a_i}\Braket{a_i|X|b_j} = \sum_{i=1}^N C_{ij} \Ket{a_i}
% \]
% siendo $C_{ij}$ la matriz del cambio de base.
% Se puede escribir
% \[
% 	\Ket{b_j} = \sum_{i=1}^N \Ket{a_i}\Braket{a_i|b_j} 
% \]
% y se ve que $\Braket{a_i|b_j}$ son los elementos de la matriz que cambia de base.
% 
% \subsection{Representación diagonal}
% 
% Un operador tiene representación diagonal cuando está representado en la base de sus
% autokets
% \[
% 	A = \sum_i^N\sum_j^N \Ket{a_i}\Braket{a_i|A|a_j}\Bra{a_j} =
% 		\sum_i^N\sum_j^N a_j\Ket{a_i}\Braket{a_i|a_j}\Bra{a_j} =
% 		\sum_{i,j}^N \delta_{ij} a_j \Ket{a_i}\Bra{a_j} = \sum_i^N a_i \mathbb{1}
% \]
% \[
% 	A = \begin{pmatrix} 
% 		a_1 & 0 & ... & 0 \\
% 		0 & a_2 & ... & 0 \\
% 		0 & 0 & ... & 0 \\
% 		0 & 0 & ... & a_n \\
% 	\end{pmatrix}
% \]
% y $a_1,a_2,...,a_n$ son sus autovalores.
% Es destacable que es conveniente utilizar como bases los autoestados de ciertos operadores.
% 
% \subsection{Representaciones canónicas}
% 
% Podemos representar una base como vectores canónicos
% \[
% 	\Ket{a_1} = \begin{pmatrix}
% 			1 \\
% 			0 \\
% 			. \\
% 			. \\
% 			N
% 			\end{pmatrix} \qquad 
% 	\Ket{a_1} = \begin{pmatrix}
% 			0 \\
% 			1 \\
% 			. \\
% 			. \\
% 			N
% 			\end{pmatrix} \qquad 
% 	\Ket{a_n} = \begin{pmatrix}
% 			0 \\
% 			0 \\
% 			. \\
% 			. \\
% 			1
% 			\end{pmatrix}
% \]
% luego 
% \[
% 	\Ket{\alpha} = \sum_i \Ket{a_i}\Braket{a_i|\alpha} =
% 		\Braket{a_1|\alpha} \begin{pmatrix}
% 			1 \\
% 			0 \\
% 			. \\
% 			. \\
% 			N
% 			\end{pmatrix} +
% 		\Braket{a_2|\alpha} \begin{pmatrix}
% 			0 \\
% 			1 \\
% 			. \\
% 			. \\
% 			N
% 			\end{pmatrix} +
% 			... +
% 		\Braket{a_n|\alpha} \begin{pmatrix}
% 			0 \\
% 			0 \\
% 			. \\
% 			. \\
% 			1
% 			\end{pmatrix} =
% \]
% \[
% 	\begin{pmatrix}
% 		\Braket{a_1|\alpha} \\
% 		\Braket{a_2|\alpha} \\
% 			... \\
% 			... \\
% 		\Braket{a_n|\alpha}
% 	\end{pmatrix}
% \]
% y por DC se tiene 
% \[
% 	\Bra{\alpha} = ( \Braket{\alpha|a_1} \Braket{\alpha|a_2} ... \Braket{\alpha|a_n} )
% \]
% y 
% \[
% 	\Braket{\alpha|\alpha} = 1 = \overbrace{( \phantom{1} \qquad \phantom{1} )}^{1\times 
% N}\overbrace{\begin{pmatrix} \phantom{1} \\ 	\phantom{1}  \end{pmatrix} }^{N\times 1} = \Box
% \]
% que es un escalar.
% \[
% 	\Braket{\beta|\alpha} = \Braket{\beta|a_i} \Braket{a_i|\alpha} = 
% 	\sum_i^N \Bra{\beta} \underbrace{\Ket{a_i} \Braket{a_i}}^{\Lambda_{a_i}} \Ket{\alpha} = \Box 
% \]
% otra vez un escalar.
% \[
% 	\Braket{a_i|\gamma} = \Braket{a_i|X|\alpha} = \sum_{a_j} \Braket{a_i|X|a_j}\Braket{a_j|\alpha}
% \]
% \[
% 	\begin{pmatrix}
% 	 \Braket{a_1|\gamma} \\
% 	 ... \\
% 	 ... \\
% 	\end{pmatrix} = 
% 	\begin{pmatrix}
% 	 X_{11} & X_{12} & ...\\
% 	 X_{21} & X_{22} & ... \\
% 	 ... \\
% 	\end{pmatrix}
% 	\begin{pmatrix}
% 	 \Braket{a_1|\alpha} \\
% 	 ... \\
% 	 ... \\	 
% 	\end{pmatrix}
% \]
% \[
% 	X = \sum_i^N \sum_j^N \Ket{a_i} \Braket{a_i|X|a_j} \Bra{a_j} =
% 		\sum_i^N \sum_j^N  \Braket{a_i|X|a_j} \Ket{a_i} \Bra{a_j}
% \]
% y esto último es una matriz. Aquí el $\hat{X}$ es una matriz y $\Braket{a_i|\hat{X}|a_j} \equiv X_{ij}$ son 
% sus elementillos (escalares).
% 
% \section{Sistemas de spín 1/2}
% 
% Hay dos estados posibles de spin $(\Ket{+}, \Ket{-})$ entonces dimensión del espacio vectorial es 2. De 
% manera que 
% \[
% 	\mathbb{1} = \Ket{+}\Bra{+} \; + \;  \Ket{-}\Bra{-}
% \]
% \[
% 	\Ket{S_z ; +} = \Ket{S_z = \hbar/2} \equiv \Bra{+} 
% \]
% \[
% 	\Ket{S_z ; -} = \Ket{S_z = -\hbar/2} \equiv \Bra{-}
% \]
% \notamargen{Acá hay que diseñar unos $+,-$ que habiten dentro de los brakets pues estos se ven feo.}
% 
% Tenemos operadores de subida y de bajada,
% \[
% 	S_+ = \hbar \Ket{+}\Bra{-} \qquad S_- = \hbar \Ket{-}\Bra{+}
% \]
% que actúan subiendo el spin o dando el ket nulo,
% \[
% 	S_+ = \hbar \begin{pmatrix} 1 \\ 0 \end{pmatrix} ( 0 \; 1 ) 
% 		= \hbar \begin{pmatrix}  0 & 1 \\ 0 & 0 \end{pmatrix}
% \]
% o bien bajando el spín o dando el ket nulo,
% \[
% 	S_- =\hbar \hbar \begin{pmatrix} 0 \\ 1 \end{pmatrix} ( 1 \; 0 ) 
% 	 = \hbar \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix}
% \]
% 
% \subsection{Cambio de base}
% 
% Dados dos conjuntos base ortonormales y completos existe un $\widehat{U}$ unitario tal que 
% \[
% 	U^+U=UU^+=\mathbb{1} \qquad \Ket{b_i}=U\Ket{a_i}
% \]
% 
% Este operador de cambio de base será 
% \[
% 	U = \sum_\ell \Ket{b_\ell}\Bra{a_\ell}
% \]
% \[
% 	U\Ket{a_i} = \sum_\ell \Ket{b_\ell}\Braket{a_\ell|a_i} = \Ket{b_i}
% \]
% que tiene por función pasar 
% \[
% 	\underbrace{\Ket{a_\ell}}_{\text{vieja base}} \longrightarrow \underbrace{\Ket{b_\ell}}_{\text{nueva base}}
% \]
% \[
% 	\Braket{b_k|\alpha} = \sum_\ell \Braket{b_k|a_\ell}  \Braket{a_\ell|\alpha}  =
% 	\sum_\ell \Braket{a_k|U^+|a_\ell}  \Braket{a_\ell|\alpha} = \Braket{a_k|U^+|\alpha} 
% \]
% 
% Entonces
% \[
% 	\Ket{\text{nueva base}} = U \Ket{\text{vieja base}}
% \]
% \[
% 	\Braket{b_i | x | b_j} = \sum_{\ell,m} \Braket{b_i|a_\ell}\Braket{a_\ell|x|a_m}\Braket{a_m|b_j }
% \]
% \[
% 	\Braket{b_i | x | b_j} = \sum_{\ell,m}\Braket{a_i|U^+|a_\ell}\Braket{a_\ell|x|a_m}\Braket{a_m|U|a_j}
% \]
% \[
% 	X_{\Ket{b}} = U^+ X_{\Ket{a}} U,
% \]
% que es una transformación de similaridad.
% 
% \subsection{Mediciones y probabilidades}
% 
% En mecánica cuántica medir es filtrar. La medición perturba al sistema. Se miden variables dinámicas asociadas a 
% observables.
% Como los autoestados de un observable $\hat{A}$ son una base completa $\{\Ket{a_i}\}$ entonces un sistema se hallará en 
% una combinación lineal de autoestados de $\hat{A}$, o al menos eso puede pensarse.
% 
% 
% \begin{tabular}{|c|c|c|}
% \hline
% antes de medir & & luego de medir \\
% \hline 
% sistema en CL
% de autestados de $\hat{A}$ & Medición de $\hat{A}$ & Salta a un autoestado de $\hat{A}$ \\
% \hline 
% sistema en 
% autoestado de $\hat{A}$  & & Continúa en autoestado de $\hat{A}$ \\
% \hline
% \end{tabular}
% 
% Puede verse pictóricamente la medición así:
% \[
% 	\Ket{\alpha} \longrightarrow \Ket{a'}
% \]
% el proceso de medición hace saltar hacia $\Ket{a'}$ siendo el resultado de la medida el autovalor $a'$.
% Luego,
% \[
% 	\mathrm{Prob}_{\Ket{a'}} \equiv |\Braket{a'|\alpha}|^2
% \]
% 
% Antes de medir no puedo saber a qué estado saltará y tampoco en qué estado se hallaba. Si $P=1$ se halla en
% $\Ket{a'}$ antes de saltar, si $P=0$ no se halla en $\Ket{a'}$ antes de saltar.
% 
% \subsection{Valor de expectación}
% 
% \[
% 	\Braket{\widehat{A}} \equiv \Braket{\alpha|A|\alpha}
% \]c
% el valor de expectación siempre se refiere a un estado en particular.
% \[
% 	\Braket{A} = \sum_{a',a''} \Braket{\alpha|a'}	\Braket{a'|A|a''} \Braket{a''|\alpha}
% \]
% \[
% 	\Braket{A} = \sum_{a',a''}  \Braket{\alpha|a'} a''\delta_{a'a''} \Braket{a''|\alpha} =
% 			\sum_{a''} a''|\Braket{\alpha|a''}|^2
% \]
% \[
% 	\Braket{A} = \sum_{a',a''} = a'' \text{Prob}_{\Ket{a''}}
% \]
% Esto último tiene el sentido de una especie de promedio ponderado.
% 
% 
% \subsection{Conmutadores}
% 
% Se definen, el conmutador
% \[
% 	[ A, B] \equiv AB - BA,
% \]
% y el anticonmutador
% \[
% 	\{ A, B \} \equiv AB + BA,
% \]
% y se dice que dos observables conmutan si $[A,B]=0$. Se dice que son compatibles si $[A,B]=0$ y anticompatibles si se 
% da la contrario, $[A,B]\neq 0$.
% 
% TEOREMA:
% 
% Sean dos observables compatibles y no degenerados, entonces los autoestados $\{ \Ket{a'}\}$ de $A$ lo son también de 
% $B$. Es decir que A y B tienen base de autoestados en común.
% 
% demostración:
% \[
% 	\Braket{a'|AB-BA|a''} = 0 
% \]
% \[
% 	a' \Braket{a'|B|a''} - \Braket{a'|B|a''} a''= (a'-a'') \Braket{a'|B|a''}= 0 
% \]
% entonces 
% \[
% 	\Braket{a'|B|a''} = 0
% \]
% y $B$ es diagonal en $\{ \Ket{a'}\}$.
% 
% Los autoestados son iguales pero no los autovalores; con lo cual se utilizará la notación $\Ket{a',b'}$ donde 
% \[
% 	A \Ket{a',b'} = a' \Ket{a',b'} \qquad \qquad B \Ket{a',b'} = b' \Ket{a',b'}
% \]
% 
% \subsection{Degeneración}
% 
% Puede darse que haya varios $g$ autoestados correspondientes a un mismo autovalor $a'$; entonces se dice que hay 
% degeneración de orden $g$ para el autoestado $\Ket{a'}$
% \[
% 	A\Ket{a'}= a'\Ket{a'} \quad ; i=1,2,...,g
% \]
% y $A$ tendrá una matriz de $m\times n$ bloques. 
% En este caso no se puede decir que la base de $A$ diagonalice a $B$.\notamargen{Mejorar la matriz que está un asco}
% \[
% 	A = \begin{pmatrix}
% 	     a'\mathbb{1} & 0 & & \\
% 	     0 & a''\mathbb{1} & & \\
% 	     & & a'''& \\
% 	     & & & a^IV \\
% 	     ...
% 	    \end{pmatrix}
% \]
% Los $\ket{a'_i}$ no dan información sobre los bloques correspondientes en la matriz de $B$.
% Necesito un conjunto de operadores que haga romper la degeneración para expresar unívocamente 
% el estado del sistema. Se llama CCOC. Necesito que conmuten entre sí para que las mediciones tengan sentido.
% 
% Si no conmutan entonces son incompatibles; la medición de uno hace saltar al sistema a un autoestado del otro y como no 
% son comunes pierde sentido el concepto de medir. No tiene sentido la medición de algo si por el hecho de medir 
% cambiamos lo que queremos medir.
% Al ser incompatibles sus mediciones de afectan mutuamente.
% 
% Los autovalores de algunos operadores podrán tener degeneración pero una combinación de los autovalores del CCOC, 
% $\Ket{a'b'c'...}$, determina el estado de forma única.
% 
% Dado un set CCOC, $\{A,B,C,D\}$, se etiquetarán $\Ket{K'} \equiv \Ket{a'b'c'd'}$ los autoestados.
% Las únicas cosas que tiene sentido medir en MC son las variables asociadas a operadores en un CCOC.
% 
% Sean $A,B$ compatibles sin degeneración
% \[
% 	\Ket{\alpha} \overbrace{\underbrace{\longrightarrow}_{a'}}^{\text{Mido A}} \Ket{a'b'}
% 	\overbrace{\underbrace{\longrightarrow}_{b'}}^{\text{Mido B}} \Ket{a'b'} 
% 	\overbrace{\underbrace{\longrightarrow}_{a'}}^{\text{Mido A}} \Ket{a'b'}
% \]
% En cambio si $A,B$ son compatibles pero con degeneración 
% \[
% 	\Ket{\alpha} \overbrace{\underbrace{\longrightarrow}_{a'}}^{\text{Mido A}} 
% 		\sum_{i=1}^g C_{a'}^{(i)}\Ket{a'b'(i)} \overbrace{\underbrace{\longrightarrow}_{b'(j)}}^{\text{Mido B}} 
% 		C_{a'}^{(j)}\Ket{a'b'(j)} \overbrace{\underbrace{\longrightarrow}_{a'(j)}}^{\text{Mido A}} 
% 		C_{a'}^{(j)} \Ket{a'b'(j)}
% \]
% 
% Al medir A y obtener $a'$ no tengo determinado el estado del sistema. Me hallaré en una CL de autoestados 
% correspondientes al autovalor degenerado $a'$. Al medir luego B selecciono uno de los $\Ket{a'b'}$ degenerados, el 
% correspondiente a $b'(j)$ pues B no está degenerado. Puedo volver a medir A pues el autoestado en que ha caído el 
% sistema permanece incólume.
% 
% 
% \subsection{Postulados de la mecánica cuántica}
% 
% \begin{enumerate}
%  \item El estado de un sistema lo definimos con un ket $\Ket{\alpha} \in \mathcal{H}$ y con $\Braket{\alpha|\alpha}=1$
%  \item Asociamos a propiedades físicas (observables) operadores hermíticos $\widehat{A}$ que operan sobre los ketes. 
% 	Los autokets $\Ket{a}$ verifican :
% \[
% 	\widehat{A}\Ket{a} = a \Ket{a}, 
% \]
% y $\{ \Ket{a} \}$ es base del espacio de kets.
%  \item Al medir una cantidad física representada por el observable $\widehat{A}$ obtenemos un autovalor $a'$.
%  Luego de medir, el estado del sistema es $\Ket{a'}$.
%  \[
% 	\Ket{\Psi} \overbrace{\underbrace{\longrightarrow}_{a'}}^{\text{Mido A}} \Ket{\Psi'} =
% 	\Ket{a}\Bra{a}\Ket{\Psi} =(\Braket{a|\Psi})\Ket{a}
%  \]
%  hecho al sistema a un autoestado de $\widehat{A}$. Quizás deba ahora normalizar. $\Braket{\Psi|\Psi}=1$
%  El esquema de arriba representa la frase ``proyectar sobre la base de autoestados''.
%  \item Las transformaciones espaciales se generan por $\vb{p}$
%  \[	
% 	[x_i,p_j] = i\hbar\delta_{ij}
%  \]
%  \item La evolución temporal la realiza $H$ (el hamiltoniano).
% \end{enumerate}
% 
% \notamargen{Extrañamente el punto 4 estaba vacío. Raro.}
% 
% \subsection{Operador de dispersión}
% 
% \[
% 	\Delta \widehat{A} \equiv \widehat{A} - \Braket{A}\mathbb{1}
% \]
% la dispersión será nula en un autoestados del operador $\widehat{A}$. Luego la dispersión cualitativamente nos dice 
% ``qué tan lejos'' del autoestado nos hallamos.
% \[
% 	\Braket{(\Delta A)^2} = \Braket{(\widehat{A} - \Braket{A}\mathbb{1})^2} =
% 	\Braket{ A^2 - 2A\Braket{A} + \Braket{A}^2 } = \Braket{A^2} - 2A\Braket{A}^2 + \Braket{A}^2 =
% 	\Braket{A^2} - \Braket{A}^2
% \]
% y la relación de dispersión generalizada
% \[
% 	\Braket{(\Delta A)^2} \Braket{(\Delta B)^2} \geq \frac{1}{4}|\Braket{[ A,B ]}|^2
% \]
% 
% \subsection{Espectro continuo}
% 
% Hay observables con espectro de autovalores continuo.
% Nos podemos construir la siguiente tabla para comparar ambos escenarios.
% 
% \begin{tabular}{|c|c|}
% \hline 
% Espectro discreto & Espectro continuo \\
% \hline
%   & \\
%   $A\Ket{a'}=a'\ket{a'}$ & $Y\Ket{y'}=y'\ket{y'}$ \\
%   & \\
%   $\mathbb{1} = \sum_{a' }^N \Ket{a'}\Bra{a'} $ & $\mathbb{1} = \int_{-\infty}^ {\infty} \Ket{y'}\Bra{y'} dy' $ \\
%   & \\
%   $\Braket{a'|a''} = \delta_{a' a''}$ & $\Braket{y'|y''} = \delta(y'-y'')$ \\
%   & \\
%   $ \sum_{a' }^N \Braket{a'|a''}\Bra{a''} = \Bra{a'}$ & $ \int_{-\infty}^\infty dy'' \Braket{y'|y''}\Bra{y''} = 
% \Bra{y'}$ \\
%   & \\
%   $ \sum_{a' }^N \Ket{a'} \Braket{a'|\alpha} =  \Ket{\alpha}$ & $ \int_{-\infty}^\infty dy' \Ket{y'}\Braket{y'|\alpha} 
% = \Ket{\alpha}$ \\
%   & \\
%   $ \sum_{a' }^N |\Braket{a'|\alpha}|^2 = 1$ & $ \int_{-\infty}^\infty dy'|\Braket{y'|\alpha}|^2 = 
% 1$ \\
%   & \\
%     $ \Braket{\beta | \alpha}  = \sum_{a' }^N \Braket{\beta|a'}\Braket{a'\alpha}$ & $ \Braket{\beta | \alpha}  = 
% \int_{-\infty}^\infty dy' \Braket{\beta|y'}\Braket{y'\alpha}$ \\
%   & \\
% \hline  
% \end{tabular} 
% 
% \subsection{La función de onda}
% 
% \[
% 	\Ket{\alpha} = \int_{\infty}^\infty dx' \Ket{x'}\Braket{x'|\alpha}
% \]
% donde 
% \[
% 	\Braket{x'|\alpha}dx'
% \]
% es la densidad de probabilidad y 
% \[
% 	|\Braket{x'|\alpha}|^2
% \]
% es la amplitud de probabilidad. La densidad de probabilidad, en el formalismo de Schrödinger, es la función de onda
% \[
% 	\Psi_\alpha(x) = \Braket{x|\alpha}
% \]
% siendo este el vínculo entre la representación de Dirac y la función de onda,
% \[
% 	\Braket{\beta|\alpha} = \int dx' \Braket{\beta|x'}\Braket{x'|\alpha} = 
% 		\int dx' \Psi_\beta^*(x) \Psi_\alpha(x)
% \]
% \[
% 	\Braket{\beta|A|\alpha} = \int \int dx' dx''\Braket{\beta|x''}\Braket{x''|A|x'}\Braket{x'|\alpha}
% \]
% \[
% 	\Braket{\beta|A|\alpha} = \int \int dx' dx'' \Psi_\beta^*(x'') \Braket{x''|A|x'} \Psi_\alpha(x')
% \]
% y si $A=f(\hat{x})$ entonces $f(\hat{x}) \Ket{x'} = f(x') \Ket{x'}$ y
% \[
% 	\Braket{\beta|A|\alpha} = \int \int dx' dx'' \Psi_\beta^*(x'') f(x')\delta(x''-x') \Psi_\alpha(x')
% \]
% y entonces 
% \[
% 	\Braket{\beta|A|\alpha} = \int dx' \Psi_\beta^*(x') f(x') \Psi_\alpha(x').
% \]
% 
% En forma análoga tenemos la representación de momento;
% \[
% 	\hat{p}\Ket{p'} = p'\Ket{p'} \qquad \Braket{p'|p''} = \delta(p'-p'') \qquad 
% 	\Ket{\alpha} = \int dp' \Ket{p'}\Braket{p'|\alpha}
% \]
% \[
% 	\Phi_\alpha(p') = \Braket{p'|\alpha}.
% \]
% 
% \subsection{Operador de traslación}
% 
% Se le pedirá
% \[
% 	\Tau_{(dx')} \Ket{x'} = \Ket{x'+dx'}
% \]
% siendo este requerimiento intuitivamente adecuado para una traslación. Nótese que $dx'$ no es un operador, es el 
% parámetro de la traslación.
% 
% Cumplirá las propiedades
% \begin{itemize}
%  \item Unitariedad:
%  \[
% 	\Tau^\dagger\Tau = \Tau \Tau^\dagger = \mathbb{1}
%  \]
%  para que no varíe la probabilidad ante un cambio de coordenadas.
%  \item Aditividad:
%  \[
% 	\Tau_{(dx')}\Tau_{(dx'')} = \Tau_{(dx'+dx'')}
%  \]
%  porque vale en mecánica clásica.
%  \item Existencia de inverso:
%  \[
% 	\Tau_{(dx')}^{-1} = \Tau_{(-dx'')}
%  \]
%  \item Límite a $\mathbb{1}$
%  \[
% 	\Tau_{(dx')} \to \mathbb{1} \quad \text{si} \quad dx' \to 0
%  \]
% \end{itemize}
% 
% Se propone un 
% \[
% 	\Tau_{(dx')} = \mathbb{1} - i \vb{K}\cdot d\vb{x}'
% \]
% con $\vb{K}$ hermítico (notemos que $\tau$ no es hermítico). Comparando con mecánica clásica vemos que \vb{p} origina 
% las traslaciones, entonces identificamos $K$ con $p$.
% \notamargen{Hay que ver el carácter vectorial de estas cosas.}
% 
% Entonces pedimos que \vb{p} cuántico origine las traslaciones
% \[
% 	\vb{K} = \frac{\vb{p}}{\hbar} \qquad \Tau_{(dx')} = \mathbb{1} - \frac{i}{\hbar} \vb{P}\cdot d\vb{x}'
% \]
% y así
% \[
% 	\Tau_{(dx')}\Ket{p'} = \left( \mathbb{1} - \frac{i}{\hbar} \vb{P}\cdot d\vb{x}' \right)\Ket{p'} =
% 	\left( 1 - \frac{i}{\hbar} p' dx \right)\Ket{p'}
% \]
% el autovalor no es real, pues $\Tau$ no es hermítico.
% 
% Partiendo del conmutador 
% \[
% 	x \Tau_{(dx')} - \Tau_{(dx')} x = dx \Tau_{(dx')}
% \]
% entonces 
% \[
% 	[x, \Tau_{(dx')}] = dx\Tau 
% \]
% y con $dx\sim 0$ a orden uno (esto significa que tiramos los términos cuadráticos en $dx$)
% \[
% 	[ x, p_x ] = i \hbar
% \]
% se llega a la incompatibilidad de posición y momento, generalizando
% \[
% 	[ x_i, p_j ] = i \hbar \delta_{ij}
% \]
% Pero las traslaciones en diferentes direcciones conmutan
% \[
% 	[ \Tau_{(d\vb{x}')}, \Tau_{(d\vb{x}'')} ] = 0  \qquad [ p_i, p_j ] = 0
% \]
% 
% Sumando infinitas traslaciones infinitesimales tenemos una traslación finita,
% \[
% 	\Tau_{(\Delta x')} = \lim_{N\to \infty}\left( 1 - \frac{i}{\hbar}p\frac{\Delta x'}{N}\right)^N 
% 		= \euler^{-i/\hbar \: p\Delta x'}
% \]
% y entonces 
% \[
% 	\Tau_{(\Delta x')} = \euler^{-i/\hbar\: \vb{p}\cdot\Delta \vb{x}'}
% \]
% 
% 
% \subsection{\vb{p} en la representación \vb{x}}
% 
% \[
% 	\Tau_{(\Delta x)} \Ket{\alpha} = \int dt' \Tau\Ket{x'}\Braket{x'|\alpha} = 
% 		\int dt' \Ket{x'+ \Delta x}\Braket{x'|\alpha} = \int dt' \Ket{x'}\Braket{x'-\Delta x|\alpha}
% \]
% pero
% \[
% 	\dpar{}{x'} \Braket{x'|\alpha} \approx \frac{ -\Braket{x'-\Delta x|\alpha} + \Braket{x'|\alpha} }{\Delta x}
% \]
% y entonces
% \[
% 	-\dpar{}{x'} \Braket{x'|\alpha} \Delta x + \Braket{x'|\alpha}  = \Braket{x'-\Delta x|\alpha}
% \]
% 
% \[
% 	\Tau\Ket{\alpha} = \int dx' \Ket{x'}\left( \Braket{x'|\alpha} -\dpar{}{x'} \Braket{x'|\alpha} \Delta x \right) =
% 	\int dx' \Ket{x'} \Braket{x'|\alpha} - \int dx' \Ket{x'}  \dpar{}{x'} \Braket{x'|\alpha} \Delta x 
% \]
% \[
% 	\left( 1 - \frac{i}{\hbar}p\Delta x \right) \Ket{\alpha} = 
% 		\Ket{\alpha} - \int dx' \Ket{x'}  \dpar{}{x'} \Braket{x'|\alpha} \Delta x
% \]
% \[
% 	\frac{i}{\hbar}p\Delta x \Ket{\alpha} = \int dx' \Ket{x'}  \dpar{}{x'} \Braket{x'|\alpha} \Delta x
% \]
% y así
% \[
% 	p\Ket{\alpha} = -i\hbar \int dx' \Ket{x'}  \dpar{}{x'} \Braket{x'|\alpha}
% \]
% de modo que usándo este resultado se tienen
% \[
% 	\Braket{x''|p|\alpha} = -i\hbar \int dx' \Braket{x''|x'}  \dpar{}{x'} \Braket{x'|\alpha}
% \]
% \[
% 	\Braket{x''|p|\alpha} = -i\hbar \dpar{}{x'} \Braket{x''|\alpha}
% \]
% \[
% 	\Braket{\beta|p|\alpha} = \int dx' \Braket{\beta|x'} (-i\hbar) \dpar{}{x'} \Braket{x'|\alpha}
% \]
% \[
% 	\Braket{\beta|p|\alpha} = \int dx' \Psi_\beta^*(x') (-i\hbar) \dpar{}{x'} \Psi_\alpha(x')
% \]
% de lo que se deduce 
% \[
% 	\hat{p} \equiv - i \hbar \dpar{}{x},
% \]
% que es el resultado más importante de la sección.
% 
% \subsection{Cambio entre representaciones \vb{x} y \vb{p} }
% 
% \[
% 	\Braket{x'|\hat{p}|p'} =  -i\hbar \int dx'  \Braket{x'|x'} \dpar{}{x'} \Braket{x'|p'} =
% 	-i\hbar \dpar{}{x'} \Braket{x'|p'}
% \]
% y entonces,
% \[
% 	p' \Braket{x'|p'} = -i\hbar \dpar{}{x'} \Braket{x'|p'},
% \]
% que es una ecuación diferencial para $\Braket{x'|p'}$. Luego
% \[
% 	\int  \frac{1}{\Braket{x'|p'}} \partial \Braket{x'|p'} = \int \frac{ip'}{\hbar} \partial x'
% \]
% \[
% 	\log \Braket{x'|p'} = \frac{ip'x'}{\hbar} + Cte.
% \]
% \[
% 	\int dp' \Braket{x'|p'} \Braket{p'|x''} = \Braket{x'|x''} = \delta(x-x')
% \]
% \[
% 	\int dp' \euler^{ip'/\hbar(x'-x'')} |N|^2 = \delta(x-x')
% \]
% \[
% 	|N| = \frac{1}{\sqrt{2\pi\hbar}}.
% \]
% \[
% 	\Braket{x'|p'} = \frac{1}{\sqrt{2\pi\hbar}} \euler^{i p'x'/\hbar}
% \]
% Con este escalar podemos cambiar entre representaciones.
% Usando esto podemos ver que $\Psi_\alpha(x')$ y $\Phi_\alpha(p')$ son transformadas de Fourier la una de la otra.
% \[
% 	 \int_{-\infty}^\infty dp \euler^{iap(x-x')} = \frac{2\pi}{a}\delta(x-x')
% \]
% 
% \subsection{Corchetes de Poisson versus conmutadores}
% 
% Hay una equivalencia entre corchetes de Poisson y conmutadores, a saber:
% \[
% 	[A, B]_{\text{classic}} \longrightarrow \frac{1}{i\hbar}[A,B]
% \]
% o
% \[
% 	[A, B]_{\text{classic}} = \sum_i \left( \dpar{A}{q_i} \dpar{B}{p_i} - \dpar{A}{p_i} \dpar{B}{q_i} \right)
% \]

% \bibliographystyle{CBFT-apa-good}	% (uses file "apa-good.bst")
% \bibliography{CBFT.Referencias} % La base de datos bibliográfica

\end{document}
